{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Omdena-NE - AML Task2 Data Wrangling.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxH3bNs0KTkJ"
      },
      "source": [
        "# [Omdena-NeedEnergy \"Increasing Clean Energy Access in Africa\" project](https://omdena.com/projects/clean-energy-ai/)\n",
        "#### A.Montesino (Feb 22nd, 2021)\n",
        "### Task 5 - Data Exploration\n",
        "\n",
        "References:\n",
        "* [Document #1](#http://www.loremipzum.com/en/)\n",
        "* [Document #2](#http://www.loremipzum.com/es/)\n",
        "* other...\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE4b_YcPKTkQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57b69ae7-b93a-42bd-9c91-e850543dbcf4"
      },
      "source": [
        "# Install common libraries\n",
        "\n",
        "# NumPy\n",
        "try:\n",
        "    import numpy as np\n",
        "    # from numpy import *\n",
        "except ImportError as e:\n",
        "    # module doesn't exist, deal with it.\n",
        "    ! pip install numpy\n",
        "print( \"NumPy version:\", np.__version__ )\n",
        "\n",
        "# xlrd required by pandas' read_excel()\n",
        "try:\n",
        "    import xlrd \n",
        "except ImportError as e:\n",
        "    # module doesn't exist, deal with it.\n",
        "    ! pip install xlrd\n",
        "\n",
        "# pandas\n",
        "try:\n",
        "    import pandas as pd\n",
        "    from pandas import *\n",
        "except ImportError as e:\n",
        "    # module doesn't exist, deal with it.\n",
        "    ! pip install pandas==0.25.0\n",
        "print( \"Pandas version:\", pandas.__version__ )    \n",
        "\n",
        "# -----------------------------------------------------------\n",
        "\n",
        "# maptplot\n",
        "try:\n",
        "    import matplotlib.pyplot as plt\n",
        "    #from pandas import *\n",
        "except ImportError as e:\n",
        "    # module doesn't exist, deal with it.\n",
        "    ! pip install pandas\n",
        "\n",
        "# Seaborn\n",
        "try:\n",
        "    import seaborn as sns\n",
        "except ImportError as e:\n",
        "    # module doesn't exist, deal with it.\n",
        "    ! pip install seaborn\n",
        "\n",
        "# Comment this if the data visualisations doesn't work on your side\n",
        "%matplotlib inline\n",
        "plt.style.use('bmh')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NumPy version: 1.19.5\n",
            "Pandas version: 1.1.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1kevzkPKTkR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79de4e68-2464-4c1f-9530-2e1424d4cb63"
      },
      "source": [
        "# pip list\n",
        "import numexpr\n",
        "numexpr.print_versions()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
            "Numexpr version:   2.7.2\n",
            "NumPy version:     1.19.5\n",
            "Python version:    3.6.9 (default, Oct  8 2020, 12:12:24) \n",
            "[GCC 8.4.0]\n",
            "Platform:          linux-x86_64-#1 SMP Thu Jul 23 08:00:38 PDT 2020\n",
            "CPU vendor:        \n",
            "CPU model:         \n",
            "CPU clock speed:    MHz\n",
            "VML available?     False\n",
            "Number of threads used by default: 2 (out of 2 detected cores)\n",
            "Maximum number of threads: 64\n",
            "-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVJbrfScbwe_"
      },
      "source": [
        "For details on accesing data from Google.Colab, through Google Drive, please go to: \r\n",
        "* [Google Colab - Local File System - API REST](https://colab.research.google.com/notebooks/io.ipynb#scrollTo=jRQ5_yMcqJiV)  \r\n",
        "* [Importing files from Google Drive in Colab - Mounting Google Drive](https://buomsoo-kim.github.io/colab/2020/05/09/Colab-mounting-google-drive.md)  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1JIzPpUKmWL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cfe3cff-e84f-46f4-e501-ac23d71828eb"
      },
      "source": [
        "# First step is getting the authorization code by loggin into your Google account. Then, paste the authorization code and press Enter.\r\n",
        "\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hB7Nl_98KTkU"
      },
      "source": [
        "## [Pandas Profiling](https://pandas-profiling.github.io/pandas-profiling/docs/master/rtd/pages/introduction.html)\n",
        "\n",
        "EDA using the pandas-profiling package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yp7eRy8KTkU"
      },
      "source": [
        "# First install and import required packages\n",
        "\n",
        "# Pandas_Profiling requires a version of pandas that still suppors the join_axes parameter in the concat() method \n",
        "# !pip install pandas==0.25.0\n",
        "\n",
        "try:\n",
        "    from pandas_profiling import ProfileReport\n",
        "    import pandas_profiling as pd_pfl \n",
        "except ImportError as e:\n",
        "    # module doesn't exist, deal with it.\n",
        "    ! pip install pandas-profiling\n",
        "    \n",
        "def generateEDAreport_pandasProfile( p, sourceFileName ):\n",
        "    print( \"Generating Pandas Profiling EDA report for '%s'\" % sourceFileName )\n",
        "    print( \"Dataframe rows %d\" % len( p.index ) )\n",
        "    # profile = ProfileReport( p, title='Pandas Profiling Report', html={'style':{'full_width':True}} )\n",
        "    profile = ProfileReport( p )\n",
        "\n",
        "    REPORT_DIRECTORY_PATH =os.path.join( os.path.split( sourceFileName )[ 0 ], \"EDA_reports\" )   # Currently not used\n",
        "    # if not os.path.exists( REPORT_DIRECTORY_PATH ):\n",
        "    # os.mkdir( REPORT_DIRECTORY_PATH )\n",
        "    print( \"Tentative destination report for reports '%s'\" % REPORT_DIRECTORY_PATH)  \n",
        "    \n",
        "    # Saving results to a HTML file\n",
        "    REPORT_SUFFIX =\"_pandasProfl.html\"\n",
        "    OUTPUT_FILE = os.path.join( REPORT_DIRECTORY_PATH, os.path.split( sourceFileName )[ 1 ]+REPORT_SUFFIX )\n",
        "    print( \"Outputfile:\", OUTPUT_FILE )\n",
        "    # profile.to_file( OUTPUT_FILE )\n",
        "\n",
        "    # Outputting results inline, as part of the current notebook\n",
        "    profile.to_notebook_iframe()\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4777Nju7KTkU"
      },
      "source": [
        "## [Sweetviz](https://github.com/fbdesignpro/sweetviz)\n",
        "\n",
        "EDA using the SweetViz package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96R747yvKTkV"
      },
      "source": [
        "# First install and import required packages\n",
        "try:\n",
        "    import pandas as pd\n",
        "except ImportError as e:\n",
        "    # module doesn't exist, deal with it.\n",
        "    ! pip install pandas\n",
        "\n",
        "try:\n",
        "    import sweetviz as sv\n",
        "except ImportError as e:\n",
        "    # module doesn't exist, deal with it.\n",
        "    ! pip install sweetviz\n",
        "\n",
        "#EDA using Sweetviz\n",
        "def generateEDAreport_sweetViz( p, sourceFileName ):\n",
        "    print( \"Generating SweetViz EDA report for '%s'\" % sourceFileName )\n",
        "    print( \"Dataframe rows %d\" % len( p.index ) )\n",
        "    sweet_report = sv.analyze( p )\n",
        "     \n",
        "    # Saving results to HTML file\n",
        "    \n",
        "    # Invocation without any arguments will generate a \"SWEETVIZ_REPORT.html\" output file, without any prefix linking it to the source file.\n",
        "    # sweet_report.show_html( )\n",
        "    REPORT_DIRECTORY_PATH =os.path.join( os.path.split( sourceFileName )[ 0 ], \"EDA_reports\" )   # Currently not used\n",
        "    if not os.path.exists( REPORT_DIRECTORY_PATH ):\n",
        "        os.mkdir( REPORT_DIRECTORY_PATH )\n",
        "    # print( \"Tentative destination report for reports '%s'\" % REPORT_DIRECTORY_PATH)  \n",
        "\n",
        "    # Sending output to a specific destination directory other than working directory, however, requires invokation with explicit parameters \n",
        "    REPORT_SUFFIX =\"_sweetViz.html\"\n",
        "    OUTPUT_FILE = os.path.join( REPORT_DIRECTORY_PATH, os.path.split( sourceFileName )[ 1 ]+REPORT_SUFFIX )\n",
        "    # print( \"Outputfile:\", OUTPUT_FILE )\n",
        "    \n",
        "    # sweet_report.show_html( filepath=OUTPUT_FILE, open_browser=False, layout='widescreen', scale=None )\n",
        "    sweet_report.show_html( filepath=OUTPUT_FILE, open_browser=False )\n",
        " \n",
        "    # Outputting results inline, as part of the current notebook\n",
        "    # sweet_report.show_notebook( )"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DSO8W8KKTkV"
      },
      "source": [
        "## [Autoviz](https://github.com/AutoViML/AutoViz/blob/master/README.md)\n",
        "\n",
        "EDA using the Autoviz package\n",
        "\n",
        "References:\n",
        "\n",
        "* [AutoViz: A New Tool for Automated Visualization, Dan Roth, Medium](https://towardsdatascience.com/autoviz-a-new-tool-for-automated-visualization-ec9c1744a6ad)  \n",
        "_An XGBoost model is repeatedly used to determine the most consistent set of features determined to be important by using a random set of features each time; the most prominent selected features can then serve to guide future plotting and visualization. ... To do this effectively, AutoViz classifies the selected variables as categorical, numerical, boolean, NLP text and so on in order to understand how to best plot them._  \n",
        "_Finally, using in-built heuristics, the tool will return the visuals deemed to have the greatest impact. AutoViz is also very much systematic: it uses all the selected variables with different chart types in order to deliver the best insights by letting the charts speak for themselves. ... AutoViz’ objective selection of features and plots can point data teams towards the best approaches using a systematic methodology and can greatly enhance a team’s productivity from the very outset of a project._  \n",
        "_Check [notebook AutViz_test.ipynb](https://github.com/DanRothDataScience/autoviz_test/blob/master/AutoViz_test.ipynb) for an example notebook._\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CcgzrWxKTkV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a11d2331-1b36-46d4-9fe0-b3b2d2b1b9e9"
      },
      "source": [
        "# First install and import required packages\n",
        "try:\n",
        "    import pandas as pd\n",
        "except ImportError as e:\n",
        "    # module doesn't exist, deal with it.\n",
        "    import pandas as pd\n",
        "\n",
        "try:\n",
        "    from autoviz.AutoViz_Class import AutoViz_Class\n",
        "except ImportError as e:\n",
        "    # module doesn't exist, deal with it.\n",
        "    ! pip install autoviz\n",
        "\n",
        "#EDA using Sweetviz\n",
        "def generateEDAreport_AutoViz( p, sourceFileName, targetVariable ):\n",
        "    print( \"Generating AutoViz EDA report for '%s'\" % sourceFileName )\n",
        "    print( \"Dataframe rows %d\" % len( p.index ) )\n",
        "    sweet_report = sv.analyze( p )\n",
        "     \n",
        "    # Saving results to HTML file is apparently not possible\n",
        "    \n",
        "    REPORT_DIRECTORY_PATH =os.path.join( os.path.split( sourceFileName )[ 0 ], \"EDA_reports\" )   # Currently not used\n",
        "    if not os.path.exists( REPORT_DIRECTORY_PATH ):\n",
        "        os.mkdir( REPORT_DIRECTORY_PATH )\n",
        "    print( \"Tentative destination report for reports '%s'\" % REPORT_DIRECTORY_PATH)  \n",
        "\n",
        "    # Sending output to a specific destination directory other than working directory, however, requires invokation with explicit parameters \n",
        "    REPORT_SUFFIX =\"_AutoViz.html\"\n",
        "    OUTPUT_FILE = os.path.join( REPORT_DIRECTORY_PATH, os.path.split( sourceFileName )[ 1 ]+REPORT_SUFFIX )\n",
        "    print( \"Outputfile:\", OUTPUT_FILE )\n",
        "    \n",
        "    # EDA using AutoViz\n",
        "\n",
        "    # verbose option\n",
        "    #     if 0, display minimal information but displays charts on your notebook\n",
        "    #     if 1, print extra information on the notebook and also display charts\n",
        "    #     if 2, you will not see any charts but they will be quietly generated and save in your local current directory under the AutoViz_Plots directory\n",
        "    #           which will be created. Make sure you delete this folder periodically, otherwise, you will have lots of charts saved here if you used verbose=2 option a lot.\n",
        "    # OUTPUT_FILE =INPUT_FILE+\"/\"+\"AutoViz_Plots\"\n",
        "    # autoviz = AutoViz_Class().AutoViz( INPUT_FILE_PATH, verbose=0 )\n",
        "    autoviz = AutoViz_Class().AutoViz( \n",
        "        filename='',\n",
        "        sep=\",\",\n",
        "        depVar=targetVariable,\n",
        "        dfte= p,\n",
        "        header=0,\n",
        "        verbose=1,\n",
        "        lowess=False,\n",
        "        chart_format=\"svg\",\n",
        "        max_rows_analyzed=150000,\n",
        "        max_cols_analyzed=30\n",
        "    )"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Imported AutoViz_Class version: 0.0.81. Call using:\n",
            "    from autoviz.AutoViz_Class import AutoViz_Class\n",
            "    AV = AutoViz_Class()\n",
            "    AV.AutoViz(filename, sep=',', depVar='', dfte=None, header=0, verbose=0,\n",
            "                            lowess=False,chart_format='svg',max_rows_analyzed=150000,max_cols_analyzed=30)\n",
            "Note: verbose=0 or 1 generates charts and displays them in your local Jupyter notebook.\n",
            "      verbose=2 saves plots in your local machine under AutoViz_Plots directory and does not display charts.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "nYCSRvtw46kO",
        "outputId": "efda3554-87d4-49e6-947a-8d59fbf2ef1f"
      },
      "source": [
        "# New to both ways of manipulating file paths, os.path and libpath libs, and will develop this, its libpath equivalent\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# Loop recursively through directories, looking for relevant files type.\n",
        "# DATA_ROOT_DIR = Path(\"C:/Users/alvar/OneDrive/Personal/Data\")\n",
        "DATA_ROOT_DIR = Path( \"/content/drive/MyDrive/Data\" )\n",
        "DATA_ROOT_DIR = DATA_ROOT_DIR / \"Long Term Datasets\"\n",
        "\n",
        "if not DATA_ROOT_DIR.exists():\n",
        "  print( \"Root data directory does not exist:'%s'\" % DATA_ROOT_DIR )\n",
        "\n",
        "\n",
        "# Certain files to be excluded from search because of the impact that their layout has on pandas'\n",
        "# abilityto read table contents\n",
        "exclusionList = [ \n",
        "      'electricity-domestic-consumption-data.xls',\n",
        "      'renewable-in-electricity-production-share.xls',\n",
        "      'Data Documentation Sheet.xlsx',\n",
        "      'Solar_Met_Daily_19980101_20210202_Harare.csv'\n",
        "]\n",
        "\n",
        "# Recursive walk through files in DATA_ROOT_DIR\n",
        "for path in DATA_ROOT_DIR.rglob(\"*\"):\n",
        "    print( \"Path:\", os.fspath( path ) )\n",
        "    if path.name in exclusionList:\n",
        "        print( \"File is to be explictly excluded from processing\" )\n",
        "        continue\n",
        "    if path.suffix in [ '.csv' ]:\n",
        "        print( \"CSV file\" )  \n",
        "        p = pd.read_csv( os.fspath( path ) )\n",
        "    elif path.suffix in [ '.xlsx', '.xlsm', '.xls' ]:\n",
        "        print( \"EXCEL file\" )     \n",
        "        p = pd.read_excel( os.fspath( path ) )\n",
        "    else:\n",
        "        # print( \"File not among formats of interest\" )\n",
        "        continue   \n",
        "    p.head( 3 ) \n",
        "    generateEDAreport_sweetViz( p, os.fspath( path ) )\n",
        "    \n",
        "    # Invoking the following function has shown that the Pandas_Profiling module apparently has a dependency on pandas version 0.25.0 \n",
        "    # which interferes with the pandas version required by other EDA libraries. I will therefore disable invocation of this EDA library for the time being.\n",
        "    # generateEDAreport_pandasProfile( p, os.fspath( path ) )\n",
        "    \n",
        "    # Invoking the following function results in launching of a separate web page requiring human interactive input which, in spite of the apparent richness\n",
        "    # of features, makes it unsuitable for processing a large number of files. I will therefore disbale invocation of this EDA libraries for the time being.  \n",
        "    # generateEDAreport_AutoViz( p, os.fspath( path ), targetVariable ):\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Path: /content/drive/MyDrive/Data/Long Term Datasets/Energy Consumption\n",
            "Path: /content/drive/MyDrive/Data/Long Term Datasets/Weather and Solar Irradiance\n",
            "Path: /content/drive/MyDrive/Data/Long Term Datasets/Socioeconomics \n",
            "Path: /content/drive/MyDrive/Data/Long Term Datasets/Weather and Solar Irradiance/NASA POWER Solar and Met Data 20-years\n",
            "Path: /content/drive/MyDrive/Data/Long Term Datasets/Weather and Solar Irradiance/Zimbabwe Hourly Weather Data\n",
            "Path: /content/drive/MyDrive/Data/Long Term Datasets/Weather and Solar Irradiance/Renewables Ninja Hourly Weather and Solar Irradiance\n",
            "Path: /content/drive/MyDrive/Data/Long Term Datasets/Weather and Solar Irradiance/Zimbabwe Hourly Sat Weather and 5 min Solar Data\n",
            "Path: /content/drive/MyDrive/Data/Long Term Datasets/Weather and Solar Irradiance/NASA POWER Solar and Met Data 20-years/Solar_Met_Daily_19980101_20210202_Harare.csv\n",
            "CSV file\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-e762ad44b8ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuffix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;34m'.csv'\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"CSV file\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuffix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;34m'.xlsx'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.xlsm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.xls'\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"EXCEL file\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2157\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2158\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 24, saw 19\n"
          ]
        }
      ]
    }
  ]
}